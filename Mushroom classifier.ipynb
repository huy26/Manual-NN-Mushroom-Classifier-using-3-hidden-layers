{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mushroom classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyfU1oDn60Lo"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, auc, roc_curve\n",
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujiHSMdY7dt1"
      },
      "source": [
        "df = pd.read_csv('data/mushroom/mushrooms.csv')\n",
        "df.columns\n",
        "# Encode the label\n",
        "labelencoder=LabelEncoder()\n",
        "for column in df.columns:\n",
        "    df[column] = labelencoder.fit_transform(df[column])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxGlWzfV7mB7"
      },
      "source": [
        "# Preprocessing the train and test set\n",
        "X_train, X_test = train_test_split(df, train_size = 0.8)\n",
        "y_train = X_train.pop('class')\n",
        "y_test = X_test.pop('class')\n",
        "X_train = X_train.to_numpy()\n",
        "X_test = X_test.to_numpy()\n",
        "y_train = y_train.to_numpy()\n",
        "y_test = y_test.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsjnWXSs7n7l"
      },
      "source": [
        "#Calcualte sigmoid function\n",
        "def sigmoid(z):\n",
        "    \n",
        "    s = 1 / (1+ np.exp(-z))\n",
        "    return s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VPButsG7rTP"
      },
      "source": [
        "#Initialize weights\n",
        "def initialize(n_x, n_h1, n_h2, n_h3, n_y):\n",
        "    W1 = np.random.uniform(-0.05,0.05, (n_h1+1,n_x+1))\n",
        "    W2 = np.random.uniform(-0.05,0.05, (n_h2+1,n_h1+1))\n",
        "    W3 = np.random.uniform(-0.05,0.05, (n_h3+1, n_h2+1))\n",
        "    W4 = np.random.uniform(-0.05, 0.05, (n_y,n_h3+1))\n",
        "    parameters = {\"W1\": W1,\n",
        "                 \"W2\": W2,\n",
        "                 \"W3\": W3,\n",
        "                 \"W4\": W4}\n",
        "    return parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gC-034OQ7tTv"
      },
      "source": [
        "#Return layer sizes\n",
        "def layer_sizes(X, Y, n_h1, n_h2, n_h3):\n",
        "    \"\"\"\n",
        "    n_x -- the size of the input layer\n",
        "    n_h -- the size of the hidden layer\n",
        "    n_y -- the size of the output layer\n",
        "    \n",
        "    \"\"\"\n",
        "    n_x = X\n",
        "    n_h1 = n_h1\n",
        "    n_h2 = n_h2\n",
        "    n_h3 = n_h3\n",
        "    n_y = Y\n",
        "    return(n_x, n_h1, n_h2, n_h3, n_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAPHr1HA7t3U"
      },
      "source": [
        "#Forward propagation\n",
        "def forward_propagation(X, parameters):\n",
        "    W1 = parameters[\"W1\"]\n",
        "    W2 = parameters[\"W2\"]\n",
        "    W3 = parameters[\"W3\"]\n",
        "    W4 = parameters[\"W4\"]\n",
        "    \n",
        "    Z1 = np.dot(W1,X)\n",
        "    # Calcualate activation of output of input layer\n",
        "    A1 = np.tanh(Z1)\n",
        "    Z2 = np.dot(W2, A1)\n",
        "    # Calcualate activation of output of hidden layer\n",
        "    A2 = np.tanh(Z2)\n",
        "    Z3 = np.dot(W3, A2)\n",
        "    A3 = np.tanh(Z3)\n",
        "    Z4 = np.dot(W4, A3)\n",
        "    A4 = sigmoid(Z4)\n",
        "    cache = {\"Z1\": Z1,\n",
        "            \"A1\": A1,\n",
        "            \"Z2\": Z2,\n",
        "            \"A2\": A2,\n",
        "            \"Z3\": Z3,\n",
        "            \"A3\": A3,\n",
        "            \"Z4\": Z4,\n",
        "            \"A4\": A4}\n",
        "    return A4, cache"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MqRzN_M7vtg"
      },
      "source": [
        "# Back propagation\n",
        "def backward_propagation(parameters, cache, X, Y, learning_rate, alpha, prev_dWkj, prev_dWji, prev_dWjj2, prev_dWjj3, n_h1, n_h2, n_h3, num_features):\n",
        "    W1 = parameters['W1']\n",
        "    W2 = parameters['W2']\n",
        "    W3 = parameters[\"W3\"]\n",
        "    W4 = parameters[\"W4\"]\n",
        "    \n",
        "    A1 = cache['A1']\n",
        "    A2 = cache['A2']\n",
        "    A3 = cache[\"A3\"]\n",
        "    A3 = np.reshape(A3, ((n_h3+1,1)))\n",
        "    A4 = cache[\"A4\"]\n",
        "    # Create target value\n",
        "    target = Y\n",
        "    # Calulate error of output\n",
        "    if(target==1):\n",
        "        dk =  A4*(1-A4)*(0.9 - A4)\n",
        "    else:\n",
        "        dk =  A4*(1-A4)*(0.1 - A4)\n",
        "    # dk =  A4*(1-A4)*(target - A4)\n",
        "    dk = np.reshape(dk,(1,1))\n",
        "    #print(dk)\n",
        "    # Calulate error of hidden layer 3\n",
        "    dj3 = (1-A3**2)*np.dot(W4.T,dk)\n",
        "    dj3 = np.reshape(dj3,(n_h3+1,1))\n",
        "    # Calculate error of hidden layer 2\n",
        "    dj2 = (1- A2**2)*np.dot(W3.T,dj3).T\n",
        "    dj2 = np.reshape(dj2,(n_h2+1,1))\n",
        "    #Calculate error of hidden layer 1\n",
        "    dj1 = (1-A1**2)*np.dot(W2.T,dj2).T\n",
        "    dj1 = np.reshape(dj1,(n_h1+1,1))\n",
        "    # Calulate gradient descent of hidden-to-output weight\n",
        "    dWkj = learning_rate*dk*A3.T + alpha*prev_dWkj\n",
        "    # Calculate gradient descent of hidden layer 2 to hidden layer 3\n",
        "    dWjj3 = learning_rate*dj3*A2.T + alpha*prev_dWjj3\n",
        "    # Calculate gradient descent of hidden layer 1 to hidden layer 2\n",
        "    dWjj2 = learning_rate*dj2*A1.T + alpha*prev_dWjj2\n",
        "    # Calulate gradient descent of input-to-hidden weight \n",
        "    dWji = learning_rate*dj1*X + alpha*(prev_dWji)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    grads = {\"dWkj\": dWkj,\n",
        "             \"dWjj3\": dWjj3,\n",
        "             \"dWjj2\": dWjj2,\n",
        "             \"dWji\": dWji}\n",
        "    return grads"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzNl9Gcg7yt-"
      },
      "source": [
        "# Update weight\n",
        "def update_parameters(parameters, grads):\n",
        "    W1 = parameters['W1']\n",
        "    W2 = parameters['W2']\n",
        "    W3 = parameters['W3']\n",
        "    W4 = parameters['W4']\n",
        "    # gradient descent of hidden-to-output weight\n",
        "    dWkj = grads[\"dWkj\"]\n",
        "    # gradient descent of hidden 2 to hidden 3 weight\n",
        "    dWjj3 = grads[\"dWjj3\"]\n",
        "    # gradient descent of hidden 1 to hidden 2 weight\n",
        "    dWjj2 = grads[\"dWjj2\"]\n",
        "    # gradient descent of input-to-hidden weight\n",
        "    dWji = grads[\"dWji\"]\n",
        "    \n",
        "    # Update input-to-hidden weight\n",
        "    W1 = W1 + dWji\n",
        "     # Update hidden-to-hidden weight\n",
        "    W2 = W2 + dWjj2\n",
        "     # Update hidden-to-hidden weight\n",
        "    W3 = W3 + dWjj3\n",
        "    # Update hidden-to-output weight\n",
        "    W4 = W4 + dWkj\n",
        "    \n",
        "    parameters = {\"W1\": W1,\n",
        "                  \"W2\": W2,\n",
        "                 \"W3\": W3,\n",
        "                 \"W4\": W4}\n",
        "    return parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbTLT6yA70xd"
      },
      "source": [
        "# Predict if highest activation is match with label or not\n",
        "def predict(parameters, X, Y):\n",
        "    A4, cache = forward_propagation(X, parameters)\n",
        "    predicted = 1 if A4 >= 0.5 else 0\n",
        "    prediction = 1 if predicted == Y else 0\n",
        "    return prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EOcbhek72gg"
      },
      "source": [
        "# Training the model\n",
        "def model(train_x, train_y, test_x, test_y, n_h1, n_h2, n_h3, num_iterations, num_features):\n",
        "    n_x = layer_sizes(train_x.shape[1],num_features,n_h1, n_h2, n_h3)[0]\n",
        "    n_y = layer_sizes(train_x.shape[1], 1,n_h1, n_h2, n_h3)[4]\n",
        "    \n",
        "    # Initialize weights\n",
        "    parameters = initialize(n_x, n_h1, n_h2, n_h3, n_y)\n",
        "    #train_x = np.append(train_x, parameters[\"b1\"])\n",
        "    \n",
        "    # Initialize prev delta_Wkj and prev delta_Wji  \n",
        "    prev_dWkj= np.zeros((1,n_h3+1)) \n",
        "    prev_dWjj3 = np.zeros((n_h3+1, n_h2+1))\n",
        "    prev_dWjj2 = np.zeros((n_h2+1, n_h1+1))\n",
        "    prev_dWji= np.zeros((n_h1+1, num_features+1))\n",
        "    \n",
        "    accuracy_train = []\n",
        "    accuracy_test = []\n",
        "    \n",
        "    confusion_matrix_train = []\n",
        "    \n",
        "    confusion_matrix_test = []\n",
        "    \n",
        "    \n",
        "    # Loop through the epochs\n",
        "    for i in range(0, num_iterations):\n",
        "        pred_train = []\n",
        "        pred_test = []\n",
        "        \n",
        "        pred_list_train = []\n",
        "        actual_list_train = []\n",
        "        \n",
        "        pred_list_test = []\n",
        "        actual_list_test = []\n",
        "        \n",
        "        \n",
        "        #Training the model\n",
        "        for j in range(len(train_x)):   \n",
        "            actual_list_train.append(train_y[j])\n",
        "            # Add bias node\n",
        "            X = np.append(train_x[j], 1)\n",
        "        \n",
        "            A4, cache = forward_propagation(X, parameters)\n",
        "            \n",
        "            pred_list_train.append(A4>=0.5)\n",
        "            \n",
        "            predicted = predict(parameters, X,train_y[j])\n",
        "        \n",
        "            grads = backward_propagation(parameters, cache, X, train_y[j], 0.1, 0, prev_dWkj, prev_dWji, prev_dWjj2, prev_dWjj3, n_h1, n_h2, n_h3, num_features)\n",
        "            prev_dWkj = grads[\"dWkj\"]\n",
        "            prev_dWji = grads[\"dWji\"]\n",
        "            prev_dWjj2 = grads[\"dWjj2\"]\n",
        "            prev_dWjj3 = grads[\"dWjj3\"]\n",
        "            \n",
        "            parameters = update_parameters(parameters, grads)\n",
        "            \n",
        "            pred_train.append(predicted)\n",
        "        count = 0\n",
        "        for i in pred_train:\n",
        "            if i == 1:\n",
        "                count+=1\n",
        "        accuracy_train.append(float(count)/len(train_y)*100)\n",
        "        confusion_matrix_train.append(confusion_matrix(actual_list_train,pred_list_train))\n",
        "        \n",
        "        # Test the model with test set\n",
        "        for j in range(len(test_x)):   \n",
        "            actual_list_test.append(test_y[j])\n",
        "            \n",
        "            # Add bias node\n",
        "            X = np.append(test_x[j], 1)\n",
        "        \n",
        "            A4, cache = forward_propagation(X, parameters)\n",
        "            pred_list_test.append(A4>=0.5)\n",
        "            predicted = predict(parameters, X,test_y[j])\n",
        "\n",
        "            pred_test.append(predicted)\n",
        "        count = 0\n",
        "        for i in pred_test:\n",
        "            if i == 1:\n",
        "                count+=1\n",
        "        accuracy_test.append(float(count)/len(test_y)*100)\n",
        "        \n",
        "        confusion_matrix_test.append(confusion_matrix(actual_list_test, pred_list_test))\n",
        "                \n",
        "    return accuracy_train, accuracy_test, parameters, confusion_matrix_train, confusion_matrix_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNaZBPTd75Hq"
      },
      "source": [
        "acc_train, acc_test,parameters, cm_train, cm_test = model(X_train, y_train, X_test, y_test, 3, 3, 3, 50, 22)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTAPW-CX78SU"
      },
      "source": [
        "plt.plot(acc_train, label = 'train')\n",
        "plt.plot(acc_test, label = 'test')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend()\n",
        "plt.show\n",
        "\n",
        "for i in cm_test:\n",
        "    print(i)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}